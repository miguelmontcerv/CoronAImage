{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modelo-covid19-rx.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RgqsFqM9AEd3",
        "SXo4cBru_3CO",
        "9nG7eSb6WIYq",
        "FZEKHDUv8Xrw",
        "zeExG0brtBrb",
        "w9166quX6UNw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNx_gGBfhFuu"
      },
      "source": [
        "---\n",
        "# **RED NEURONAL CONVOLUCIONAL (MODELO DEEP LEARNING)**\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgqsFqM9AEd3"
      },
      "source": [
        "\n",
        " ## **INICIO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skW3MJ4ijUhs"
      },
      "source": [
        "**Seteando Tensorflow 1.x:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soM9D9lkjduu"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V8VW9tajxTc"
      },
      "source": [
        "**Montando Google Drive:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sNr5weJeQNu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw3XAlZVoRyG"
      },
      "source": [
        "**Obteniendo el dataset en formato .zip**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoTRcpNokv9F"
      },
      "source": [
        "%%bash\n",
        "cd \"/content/drive/My Drive/udemy/deep-learning/covid19-rx-project/dataset\"\n",
        "\n",
        "# validar si dataset (zip) existe y descargar\n",
        "FILE=covid19_dataset.zip\n",
        "if [ ! -f \"$FILE\" ]; then\n",
        "    echo \"Archivo $FILE no existe --> Descargando ...\"\n",
        "    gdown --id 1ohGQU6g79aWB6WEf-QQUfPGf1sE4favu\n",
        "fi\n",
        "\n",
        "# borrar carpetas train y test antes de descomprimir\n",
        "rm -rf train test\n",
        "\n",
        "# descomprimir dataset (zip) en carpetas train y test\n",
        "unzip -qq covid19_dataset.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOdNIXrNyIVb"
      },
      "source": [
        "**Visualizando imágenes del dataset:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DooVoNDX0Mvc"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Folder del proyecto\n",
        "project_folder = \"/content/drive/My Drive/udemy/deep-learning/covid19-rx-project\"\n",
        "\n",
        "files_train_covid19 = glob.glob(project_folder+\"/dataset/train/covid19/*.jpg\")\n",
        "files_test_covid19 = glob.glob(project_folder+\"/dataset/test/covid19/*.jpg\")\n",
        "files_train_normal = glob.glob(project_folder+\"/dataset/train/normal/*.jpg\")\n",
        "files_test_normal = glob.glob(project_folder+\"/dataset/test/normal/*.jpg\")\n",
        "\n",
        "# Obteniendo imágenes al azar de cada folder\n",
        "file_train_covid19 = files_train_covid19[randrange(len(files_train_covid19))]\n",
        "image_train_covid19 = image.load_img(file_train_covid19)\n",
        "\n",
        "file_test_covid19 = files_test_covid19[randrange(len(files_test_covid19))]\n",
        "image_test_covid19 = image.load_img(file_test_covid19)\n",
        "\n",
        "file_train_normal = files_train_normal[randrange(len(files_train_normal))]\n",
        "image_train_normal = image.load_img(file_train_normal)\n",
        "\n",
        "file_test_normal = files_test_normal[randrange(len(files_test_normal))]\n",
        "image_test_normal = image.load_img(file_test_normal)\n",
        "\n",
        "# Visualizando 4 imágenes\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(8, 8)\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(image_train_covid19)\n",
        "plt.title(file_train_covid19.split(\"/\")[-1])\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(image_test_covid19)\n",
        "plt.title(file_test_covid19.split(\"/\")[-1])\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(image_train_normal)\n",
        "plt.title(file_train_normal.split(\"/\")[-1])\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.imshow(image_test_normal)\n",
        "plt.title(file_test_normal.split(\"/\")[-1])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXo4cBru_3CO"
      },
      "source": [
        "\n",
        " ## **SECCIÓN I - PREPROCESAMIENTO DE DATOS**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMqsVk3G6RDc"
      },
      "source": [
        "**Cargar dataset TRAIN y aplicar Data Augmentation:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GS-oZlc_8hD"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Dimensión de las imgs a procesar\n",
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 40\n",
        "\n",
        "# Data Augmentation and Normalization\n",
        "datagen_train = ImageDataGenerator(rescale=1.0/255.0,      # Normalizar los valores al rango [0-1]\n",
        "                                   horizontal_flip=True,   # Giro horizontal\n",
        "                                   rotation_range=15,      # Giro aleatorio (clockwise) entre 0 y 15 grados\n",
        "                                   width_shift_range=0.15,  # Mover la img horizontelmente 15%\n",
        "                                   height_shift_range=0.15, # Mover la img verticalmente 15%\n",
        "                                   zoom_range=0.2)          # Zoom in / Zoom out aleatorio de 20% => 80% - 120%\n",
        "\n",
        "# Leer imagenes del folder dataset/train\n",
        "training_set_imgs = datagen_train.flow_from_directory(project_folder+\"/dataset/train\",\n",
        "                                                      target_size = (img_width, img_height),\n",
        "                                                      class_mode = 'binary',\n",
        "                                                      classes = ['normal','covid19'],\n",
        "                                                      batch_size = batch_size)\n",
        "# Mostrando resultados\n",
        "num_imgs_training = len(training_set_imgs.filenames)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Núm. de imgs ENTRENAMIENTO:\", num_imgs_training)\n",
        "print(\"Classes:\", training_set_imgs.class_indices)\n",
        "print(\"Núm. Classes [0]:\", np.sum(training_set_imgs.labels == 0, axis=0))\n",
        "print(\"Núm. Classes [1]:\", np.sum(training_set_imgs.labels == 1, axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUwFeIpFknt_"
      },
      "source": [
        "**Mostrando datos resultado de Data augmentation:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MukVFYbVks3C"
      },
      "source": [
        "import copy \n",
        "\n",
        "# Visualizando data augmentation para 1 imagen\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(8, 8)\n",
        "\n",
        "it = copy.copy(training_set_imgs)\n",
        "\n",
        "for i in range(9):\n",
        "\tplt.subplot(3,3,1 + i)\n",
        "\tbatch = it.next()[0]\n",
        "\timagenp = (batch[0]*255).astype('uint8')\n",
        "\tplt.imshow(imagenp)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWtFB8x_VVv1"
      },
      "source": [
        "**Cargar dataset TEST sin aplicar Data Augmentation:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhQNfR5xVdbl"
      },
      "source": [
        "# Data Normalization\n",
        "datagen_test = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Leer imagenes del folder dataset/train\n",
        "testing_set_imgs = datagen_test.flow_from_directory(project_folder+\"/dataset/test\",\n",
        "                                                      target_size = (img_width, img_height),\n",
        "                                                      class_mode = 'binary',\n",
        "                                                      classes = ['normal','covid19'],\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      shuffle=False)\n",
        "# Mostrando resultados\n",
        "num_imgs_testing = len(testing_set_imgs.filenames)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Núm. de imgs TEST:\", num_imgs_testing)\n",
        "print(\"Classes:\", testing_set_imgs.class_indices)\n",
        "print(\"Núm. Classes [0]:\", np.sum(testing_set_imgs.labels == 0, axis=0))\n",
        "print(\"Núm. Classes [1]:\", np.sum(testing_set_imgs.labels == 1, axis=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nG7eSb6WIYq"
      },
      "source": [
        "## **SECCIÓN II - CONSTRUYENDO LA RED NEURONAL ARTIFICIAL (CNN) - ARQUITECTURA**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coMG-EovW-p-"
      },
      "source": [
        "**Cargar Modelo pre-entrenado DenseNet:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPOslp9a-vDn"
      },
      "source": [
        "# DenseNet https://keras.io/api/applications/densenet/\n",
        "# https://towardsdatascience.com/paper-review-densenet-densely-connected-convolutional-networks-acf9065dfefb\n",
        "from keras.applications import DenseNet201\n",
        "# ResNet https://keras.io/api/applications/resnet/\n",
        "# from keras.applications import ResNet152V2\n",
        "\n",
        "# Cargando modelo DenseNet\n",
        "pretrained_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "pretrained_model.summary();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6rND30NdG4q"
      },
      "source": [
        "**Congelar (freeze) los params en el Feature Extractor:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4fA7YY4dN6a"
      },
      "source": [
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "pretrained_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ImWhMfrhBTZ"
      },
      "source": [
        "**Agregando el clasificador propio:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkWXHj2phH-g"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Definiendo una Red Neuronal vacía\n",
        "model = Sequential()\n",
        "\n",
        "# Agregando la parte convolucional (base)\n",
        "model.add(pretrained_model)               # Modelo base\n",
        "\n",
        "# Clasificador propio\n",
        "model.add(GlobalAveragePooling2D())       # GlobalAveragePooling2D https://adventuresinmachinelearning.com/global-average-pooling-convolutional-neural-networks/\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(\"Arquitectura final:\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZEKHDUv8Xrw"
      },
      "source": [
        "## **SECCIÓN III - ENTRENANDO LA RED NEURONAL ARTIFICIAL (CNN)**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGT4luQnvtU"
      },
      "source": [
        "**Compilar la Red Neuronal Convolucional:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNvJX2GFn17d"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "opt = SGD(lr=0.008, momentum=0.9)\n",
        "# opt = Adam(lr=0.008, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# COMPILANDO la Red Neuronal Convolucional\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZjS38YsoRQK"
      },
      "source": [
        "**Entrenar la Red Neuronal convolucional:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk77_nF6kPeP"
      },
      "source": [
        "%%time\n",
        "\n",
        "epochs=20\n",
        "\n",
        "# Entrenar\n",
        "history = model.fit_generator(training_set_imgs,\n",
        "                              epochs=epochs,\n",
        "                              steps_per_epoch=np.ceil(num_imgs_training/batch_size),\n",
        "                              validation_data=testing_set_imgs,\n",
        "                              validation_steps=np.ceil(num_imgs_testing/batch_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z--XkzViqeR4"
      },
      "source": [
        "**Graficar resultados del entrenamiento:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SOW6lOXqjeh"
      },
      "source": [
        "# GRAFICANDO resultados\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(12, 8)\n",
        "\n",
        "# plot loss\n",
        "plt.subplot(2,2,1)\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(history.history['loss'], color='blue', label='train')\n",
        "\n",
        "# plot accuracy\n",
        "plt.subplot(2,2,2)\n",
        "plt.title('Classification Accuracy')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(history.history['accuracy'], color='orange', label='train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeExG0brtBrb"
      },
      "source": [
        "## **SECCIÓN IV - EVALUACIÓN DE LA RED NEURONAL ARTIFICIAL (CNN)**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LRFWMfgFjQb"
      },
      "source": [
        "**Evaluación vía 'evaluate_generator':**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyiYwevNvpMc"
      },
      "source": [
        "# Accuraccy del Test (Usar este valor como referencial solamente https://github.com/keras-team/keras/issues/6499)\n",
        "eval = model.evaluate_generator(testing_set_imgs, steps=np.ceil(num_imgs_testing/batch_size))\n",
        "\n",
        "print('\\nValidación en Test:')\n",
        "print(\"Loss: {:.4}\".format(eval[0]))\n",
        "print(\"Accuracy: {:.2%}\".format(eval[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjLLucT-F3HZ"
      },
      "source": [
        "**Evaluación vía 'predict_generator' y Matriz de Confusión:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b8poLZl63k-"
      },
      "source": [
        "# Matriz de Confusión\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "THRESHOLD=0.5\n",
        "testing_set_imgs.reset() #batch_index=0\n",
        "\n",
        "Y_pred = model.predict_generator(testing_set_imgs, steps=np.ceil(num_imgs_testing/batch_size))\n",
        "y_pred = np.where(Y_pred >= THRESHOLD, 1, 0)\n",
        "# print(Y_pred)\n",
        "# print(y_pred)\n",
        "\n",
        "cm = confusion_matrix(testing_set_imgs.classes, y_pred)\n",
        "print(\"\\nMatriz de Confusión:\\n\")\n",
        "print(cm)\n",
        "\n",
        "# print('\\nClassification Report:')\n",
        "# classes_names = ['normal', 'covid19']\n",
        "# print(classification_report(testing_set_imgs.classes, y_pred, target_names=classes_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGT9trSkU6lM"
      },
      "source": [
        "**Visualizando la Matriz de Confusión:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reRsEATJUq53"
      },
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred,\n",
        "                          normalize=False,\n",
        "                          title=None):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Matriz de Confusión Normalizada'\n",
        "        else:\n",
        "            title = 'Matriz de Confusión sin Normalizar'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    classes = unique_labels(y_true, y_pred)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Matriz de Confusión Normalizada\")\n",
        "    else:\n",
        "        print('Matriz de Confusión sin Normalizar')\n",
        "\n",
        "    # print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.grid(linewidth=.0)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    #fig.tight_layout()\n",
        "    plt.show()\n",
        "    return ax\n",
        "\n",
        "\n",
        "plot_confusion_matrix(testing_set_imgs.classes, y_pred, normalize=False,title=\"Matriz de Confusión: Covid19 vs Normal\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlFJFaPtF-Sj"
      },
      "source": [
        "**Métricas de la Matriz de Confusión:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV_X3njubaSz"
      },
      "source": [
        "# Métricas (https://en.wikipedia.org/wiki/Confusion_matrix)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "exactitud = (TP + TN)/(TP + TN + FN + FP)\n",
        "sensitividad = TP / (TP + FN)\n",
        "especificidad = TN / (TN + FP)\n",
        "prevalencia = np.sum(testing_set_imgs.classes)/len(testing_set_imgs.classes)\n",
        "\n",
        "print(\"\\nMétricas:\\n\")\n",
        "print(\"Exactitud: {:.2%}\".format(exactitud))\n",
        "print(\"Sensitividad: {:.2%}\".format(sensitividad))\n",
        "print(\"Especificidad: {:.2%}\".format(especificidad))\n",
        "print(\"Prevalencia: {:.2%}\".format(prevalencia))\n",
        "\n",
        "# ROC Curve\n",
        "AUC = roc_auc_score(testing_set_imgs.classes, y_pred)\n",
        "print(\"AUCROC: {:.2%}\".format(AUC))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9166quX6UNw"
      },
      "source": [
        "## **SECCIÓN V - GUARDANDO LA RED NEURONAL ARTIFICIAL EN DISCO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvzxoyZgGImA"
      },
      "source": [
        "**Guardando modelo en disco:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x73Nn0g-BDGE"
      },
      "source": [
        "# Guardando Arquitectura y Pesos como archivos diferentes\n",
        "model_json = model.to_json()\n",
        "with open(project_folder + \"/output/covid19_model_config.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "model.save_weights(project_folder + \"/output/covid19_model_weights.h5\")\n",
        "print(\"Modelo guardado en disco ...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beCq4wBrDWkN"
      },
      "source": [
        "# Cuardando como un único archivo\n",
        "model.save(project_folder + \"/output/covid19_model_full.h5\")\n",
        "print(\"Modelo guardado en disco ...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkDCQM1GE5B3"
      },
      "source": [
        "## **SECCIÓN VI - CARGANDO LA RED NEURONAL ARTIFICIAL EN DISCO Y REALIZANDO PREDICCIONES**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IxPyWHTGNle"
      },
      "source": [
        "**Cargando modelo de disco:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1HGFuKLFFj2"
      },
      "source": [
        "# Cargando modelo desde el disco\n",
        "from keras.models import load_model\n",
        "# load model\n",
        "loaded_model = load_model(project_folder + \"/output/covid19_model_full.h5\")\n",
        "# summarize model\n",
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAjkbpOnGSoB"
      },
      "source": [
        "**Realizando predicciones:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyx4MQROFbIP"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "\n",
        "# Cargando imagen a predecir: \n",
        "# https://radiologyassistant.nl/chest/covid-19-ct-findings-in-25-patients\n",
        "URL_image_rx_test = 'https://radiologyassistant.nl/assets/x.jpg'\n",
        "# http://www.meddean.luc.edu/lumen/meded/medicine/pulmonar/cxr/atlas/cxratlas_f.htm\n",
        "# URL_image_rx_test = 'http://www.meddean.luc.edu/lumen/meded/medicine/pulmonar/cxr/atlas/images/71bl.jpg'\n",
        "\n",
        "with urllib.request.urlopen(URL_image_rx_test) as url:\n",
        "   with open('temp.jpg', 'wb') as f:\n",
        "       f.write(url.read())\n",
        "image_test = 'temp.jpg'\n",
        "\n",
        "# load an image in PIL format\n",
        "image_to_predict = image.load_img(image_test, target_size=(img_width, img_height))\n",
        "print('Image type:',type(image_to_predict))\n",
        "print('Image size:',image_to_predict.size)\n",
        "plt.imshow(image_to_predict)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZwnM6RcMBp2"
      },
      "source": [
        "# Procesando la imagen\n",
        "test_image = image.img_to_array(image_to_predict) # Imagen como NumPy array\n",
        "test_image = np.expand_dims(test_image, axis = 0) # Reshaping de (w,h,c) --> (1,w,h,c)\n",
        "test_image = test_image.astype('float32')         # Valores de [0-255] --> [0.0-255.0]\n",
        "test_image /= 255                                 # Valores en [0.0-1.0]\n",
        "\n",
        "# Prediction\n",
        "output = loaded_model.predict(test_image)[0][0]\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlvICgyTNv_w"
      },
      "source": [
        "# Resultados\n",
        "prediction = 1 if (output >= THRESHOLD) else 0\n",
        "\n",
        "CLASSES = ['Normal', 'Covid19+']\n",
        "\n",
        "ClassPred = CLASSES[prediction]\n",
        "ClassProb = output\n",
        "\n",
        "print(\"Pedicción:\", ClassPred)\n",
        "print(\"Prob: {:.2%}\".format(ClassProb))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
